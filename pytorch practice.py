{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pytorch\n * Tensors is the fundamental data structure in pytorch.\n * it is an array which performs mathematical operations and is the building block of neural networks\n * can be created form python **lists** using **tensor.torch(list_name)** or from **numpy** array using toch.fro_numpy(**list_name**)\n * similar to numpyarrays tensors are **multidimensional** representations of their elements.\n","metadata":{}},{"cell_type":"code","source":"import torch\n\nlist =  [[1,2,3],[4,5,6]]\ntensor = torch.tensor(list) #creation of tensors using lists \n\nlist1 = [[7,8,9],[1,2,3]]\ntensor1 = torch.tensor(list1)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-26T15:14:03.814Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#Tensor attributes\n>* Tensor shape - var_name.shape\n>* Tensor datatype - var_name.dtype\n>* check which devce the tensor is loaded on (cpu/gpu) - var_name.device\n","metadata":{}},{"cell_type":"code","source":"tensor1.shape","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-26T15:14:03.848Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tensor1.dtype","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-26T15:14:03.850Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tensor.device","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-26T15:14:04.543Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Tensor operations**\n>* Tensors support various operations similar to numpy arrays\n>* tensor operations are compatible only when **r1*c1 ==r2 * c2**\n>* 1.Addition/Substraction\n>  a+b , a-b\n>* 2.element wise multiplication\n>  a*b\n>* 3. Transposition\n>\n>* 4. Matrix multiplication\n>   \n>* 5. Concatination\n\n> most numpy array operations can be performed on pytorch tensors ","metadata":{}},{"cell_type":"code","source":"a = torch.tensor([[1,2],[3,4]])\nb = torch.tensor([[5,6],[7,8]])\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-26T15:14:04.573Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a*b","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-26T15:14:04.580Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a+b","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-26T15:14:04.581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"c = a.T #transposition \nprint(c)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-26T15:14:04.585Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"d = b.T\nprint(d)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-26T15:14:04.586Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = torch.cat((a,b),dim = 1)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-26T15:14:04.588Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(result)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-26T15:14:04.591Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result.shape\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-26T15:14:04.593Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result1 = torch.cat((c,d))#dim = 1) rows badhegi\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-26T15:14:04.594Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(result1)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-26T15:14:04.596Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CREATING OUR FIRST NEURAL NETWORK \n* exploring how neural networks take input perform computations and produce outputs.\n* we will use **torch.nn** package to **create** our networks. ","metadata":{}},{"cell_type":"code","source":"# creating a basic NN with only input and output layer \nimport torch.nn as nn","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-26T15:14:04.599Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n* first layer will be an **input layer**.\n* Create input tensor with 3 features(neurons) using torch.tensor([[1,2,3],[4,5,6]]).\n* next step is to apply linear layer [a linear layer takes an input, applies a linear function and returns output].\n* linear layer takes in\n* 1. no of features in input layer **(in_features)** ensures linear layer recieves the input tensor and\n  2. 2. no. of output freatures **(out_features)** using **nn.linear function** .\n*  lastly we pass the input tensor to linear layer to generate an output .\n","metadata":{}},{"cell_type":"markdown","source":"#Getting to know the linear layer\n\n* each layer has a **.weight** and **.bias** property\n* what operation does nn.linear perform?\n*  when the input layer passes through the linear layer the operation performed is a matrix multiplication between the input_tensors and the weight followed by adding the bias.\n*  y = w*x + b - nn.linear function takes care of this \n\n* initially when we call nn.linear the weights and biases are initialized randomly, so they are yet not useful\n* networks with only linear layers are called **fully connected**.\n* ( 1 col * n rows - input layer & 1 col * n rows for linear output layer )\n* stacking multiple layers sequentially using **nn.sequential** function\n*  \n","metadata":{}},{"cell_type":"code","source":"#linear model \n\ninput_tensor = torch.tensor(\n    [[0.3471,0.4547,-0.2356]]\n)\n\n# defne our linear layer \n\nlinear_layer = nn.Linear(in_features = 3, out_features = 2)\n\n#pass input though linear layer \n\noutput = linear_layer(input_tensor)\nprint (output)\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-26T15:14:04.611Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Discovering activation functions ","metadata":{}},{"cell_type":"markdown","source":"we will now add non linearity to our models using **activation functions** \n> * Non linearity helps the model to learn more complex relationships.\n> * preactivation output is the input for activation function\n> * Sigmaoid activaton function - used for binary classification problems.\n> * e.g. - animal --> mamal or not ?\n> * nn.sigmoid() is used in last layer of the neural network\n> * sigmoid as a last step in nettwork of linear layers is equivalent to traditional logistic regression.\n> * nn.Softmax() is used for **multiclass**  classification.\n> * ","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\ninput_tensor1 = torch.tensor([[1.2,3.2,4.3]])\n\n#applying sigmoid function \n\nprobability = nn.Sigmoid()\noutput_tensor1 = probability(input_tensor1)\n\nprint(output_tensor1)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-26T15:14:04.612Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#adding sigmoid function to linear layers \n\nimport torch \nimport torch.nn as nn\n\ninput_tensor = torch.tensor([[4.3,6.1,2.3]])\n\n# creating a linear layer neural network \n\nLinear_layer = nn.Sequential(\n    nn.Linear (3,3),\n    nn.Linear(3,2),\n    nn.Linear(2,1),\n    nn.Sigmoid()\n)\n\noutput = Linear_layer(input_tensor)\nprint(output)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-26T15:14:04.614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch \nimport torch.nn as nn\n\n#create an input tensor \ninput_tensor = torch.tensor([[4.3,6.1,2.3]])\n\n#apply softmax function along that last dimension\nprobabilities = nn.Softmax(dim = 1)\noutput_tensor = probabilities(input_tensor)\n\nprint(output_tensor)\n\n#dim = -1 indicates that softmax is applied to the input tensors last dimension\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-26T15:14:04.616Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}